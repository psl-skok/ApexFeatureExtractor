{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a8de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client with API key from environment\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b07915",
   "metadata": {},
   "source": [
    "# Original Altice Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11d6586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalId</th>\n",
       "      <th>Conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Call1</td>\n",
       "      <td>[Agent] \"Thank you for choosing Optimum Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Call10</td>\n",
       "      <td>[Agent] \"Thank you for choosing Optimum Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Call100</td>\n",
       "      <td>[Agent] \"Good morning. Thank you for calling O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Call101</td>\n",
       "      <td>[Agent] \"Good morning. Thank you for calling O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Call102</td>\n",
       "      <td>[Agent] \"Hold on one second, hold on, do not d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Call103</td>\n",
       "      <td>[Agent] \"Thank you for calling Optimum. No off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call104</td>\n",
       "      <td>[Agent] \"Thank you for calling Optimum Busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Call105</td>\n",
       "      <td>[Agent] \"Thank you for calling O Business. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Call106</td>\n",
       "      <td>[Agent] \"Thank you for calling Optimum Busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Call107</td>\n",
       "      <td>[Agent] \"For calling Optimum for Business now ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NaturalId                                       Conversation\n",
       "0     Call1  [Agent] \"Thank you for choosing Optimum Busine...\n",
       "1    Call10  [Agent] \"Thank you for choosing Optimum Busine...\n",
       "2   Call100  [Agent] \"Good morning. Thank you for calling O...\n",
       "3   Call101  [Agent] \"Good morning. Thank you for calling O...\n",
       "4   Call102  [Agent] \"Hold on one second, hold on, do not d...\n",
       "5   Call103  [Agent] \"Thank you for calling Optimum. No off...\n",
       "6   Call104  [Agent] \"Thank you for calling Optimum Busines...\n",
       "7   Call105  [Agent] \"Thank you for calling O Business. Thi...\n",
       "8   Call106  [Agent] \"Thank you for calling Optimum Busines...\n",
       "9   Call107  [Agent] \"For calling Optimum for Business now ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"FullCallDataSummary.csv\").head(10)\n",
    "\n",
    "# Display the data as a table\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09599b7d",
   "metadata": {},
   "source": [
    "# Categorical Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c88d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ClassificationResult model\n",
    "class ClassificationResult(BaseModel):\n",
    "    classification: str\n",
    "    explanation: str\n",
    "\n",
    "def classify_call_transcripts(\n",
    "    classifications: List[str],\n",
    "    dataframe: pd.DataFrame,\n",
    "    context_prompt: str,\n",
    "    transcript_column: str,\n",
    "    classification_column: str = \"Classification\",\n",
    "    explanation_column: str = \"Explanation\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Classify call transcripts using LLM analysis.\n",
    "    \n",
    "    Args:\n",
    "        classifications (List[str]): List of possible classifications (including \"None\")\n",
    "        dataframe (pd.DataFrame): DataFrame with call data\n",
    "        context_prompt (str): Context/question for classification\n",
    "        transcript_column (str): Name of the column containing transcript text\n",
    "        classification_column (str): Name for the output classification column\n",
    "        explanation_column (str): Name for the output explanation column\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with added classification columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize results list\n",
    "    results: List[ClassificationResult] = []\n",
    "    \n",
    "    # Create classifications string for the prompt\n",
    "    classifications_str = \", \".join(classifications)\n",
    "    \n",
    "    # Define the system prompt\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert at analyzing sales call transcripts for classification purposes.\n",
    "    \n",
    "    Your task: {context_prompt}\n",
    "    \n",
    "    Available classifications: {classifications_str}\n",
    "    \n",
    "    For each conversation transcript, you must:\n",
    "    1. Select exactly ONE classification from the provided list\n",
    "    2. Provide a comprehensive explanation that includes:\n",
    "        - Key customer statements or behaviors that influenced your decision\n",
    "        - Any commitments, objections, or next steps mentioned\n",
    "        - Your reasoning for why this classification best fits the conversation\n",
    "    \n",
    "    Return your response as a JSON object with this exact format:\n",
    "    {{\n",
    "        \"classification\": \"selected_classification_from_list\",\n",
    "        \"explanation\": \"One sentence explaining why you chose this classification\"\n",
    "    }}\n",
    "    \n",
    "    Important: The classification must be exactly one of the provided options: {classifications_str}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Processing {len(dataframe)} conversations...\")\n",
    "    \n",
    "    # Process each conversation\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        call_id = str(row.iloc[0])  # First column is call ID\n",
    "        transcript_text = row[transcript_column]  # Use the specified column name\n",
    "        \n",
    "        if pd.isna(transcript_text):\n",
    "            # Handle missing transcript\n",
    "            results.append(ClassificationResult(\n",
    "                explanation=\"No transcript text available for analysis\",\n",
    "                classification=\"None\"\n",
    "            ))\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Create the user prompt with the conversation\n",
    "            user_prompt = f\"\"\"\n",
    "            Call ID: {call_id}\n",
    "            \n",
    "            Transcript:-\n",
    "            {transcript_text}\n",
    "            \n",
    "            Analyze this transcript and return the JSON with your classification and explanation.\n",
    "            \"\"\"\n",
    "            \n",
    "            # Make the API call using structured output\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=300,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            # Parse the response\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Parse JSON and create ClassificationResult\n",
    "            import json\n",
    "            parsed_response = json.loads(response_text)\n",
    "            result = ClassificationResult(\n",
    "                explanation=parsed_response[\"explanation\"],\n",
    "                classification=parsed_response[\"classification\"]\n",
    "            )\n",
    "            results.append(result)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing call {call_id}: {str(e)}\")\n",
    "            results.append(ClassificationResult(\n",
    "                explanation=f\"Error during processing: {str(e)}\",\n",
    "                classification=\"None\"\n",
    "            ))\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(dataframe)} conversations...\")\n",
    "    \n",
    "    print(\"Classification complete!\")\n",
    "\n",
    "    # Convert results list to DataFrame\n",
    "    results_df = pd.DataFrame([result.model_dump() for result in results])\n",
    "    \n",
    "    # Merge with original dataframe using variable column names\n",
    "    merged_df = dataframe.copy()\n",
    "    merged_df[classification_column] = results_df['classification']\n",
    "    merged_df[explanation_column] = results_df['explanation']\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6d543",
   "metadata": {},
   "source": [
    " Use Categorical Classification to Identify Call Outcome Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0b5f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 conversations...\n",
      "Processed 10/10 conversations...\n",
      "Classification complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaturalId</th>\n",
       "      <th>Conversation</th>\n",
       "      <th>stage</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Call1</td>\n",
       "      <td>[Agent] \"Thank you for choosing Optimum Busine...</td>\n",
       "      <td>Potential Interest as a Lead</td>\n",
       "      <td>The customer showed interest in the services a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Call10</td>\n",
       "      <td>[Agent] \"Thank you for choosing Optimum Busine...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer, Heather, explicitly agreed to an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Call100</td>\n",
       "      <td>[Agent] \"Good morning. Thank you for calling O...</td>\n",
       "      <td>Potential Interest as a Lead</td>\n",
       "      <td>The customer showed interest in porting their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Call101</td>\n",
       "      <td>[Agent] \"Good morning. Thank you for calling O...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer committed to the service by agree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Call102</td>\n",
       "      <td>[Agent] \"Hold on one second, hold on, do not d...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer, Rosa, explicitly committed to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Call103</td>\n",
       "      <td>[Agent] \"Thank you for calling Optimum. No off...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer committed to purchasing services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Call104</td>\n",
       "      <td>[Agent] \"Thank you for calling Optimum Busines...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer committed to upgrading their serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Call105</td>\n",
       "      <td>[Agent] \"Thank you for calling O Business. Thi...</td>\n",
       "      <td>Potential Interest as a Lead</td>\n",
       "      <td>The customer, Ali, shows interest in installin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Call106</td>\n",
       "      <td>[Agent] \"Thank you for calling Optimum Busines...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer explicitly committed to the servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Call107</td>\n",
       "      <td>[Agent] \"For calling Optimum for Business now ...</td>\n",
       "      <td>Definitive Sale on the Call</td>\n",
       "      <td>The customer committed to the service installa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NaturalId                                       Conversation  \\\n",
       "0     Call1  [Agent] \"Thank you for choosing Optimum Busine...   \n",
       "1    Call10  [Agent] \"Thank you for choosing Optimum Busine...   \n",
       "2   Call100  [Agent] \"Good morning. Thank you for calling O...   \n",
       "3   Call101  [Agent] \"Good morning. Thank you for calling O...   \n",
       "4   Call102  [Agent] \"Hold on one second, hold on, do not d...   \n",
       "5   Call103  [Agent] \"Thank you for calling Optimum. No off...   \n",
       "6   Call104  [Agent] \"Thank you for calling Optimum Busines...   \n",
       "7   Call105  [Agent] \"Thank you for calling O Business. Thi...   \n",
       "8   Call106  [Agent] \"Thank you for calling Optimum Busines...   \n",
       "9   Call107  [Agent] \"For calling Optimum for Business now ...   \n",
       "\n",
       "                          stage  \\\n",
       "0  Potential Interest as a Lead   \n",
       "1   Definitive Sale on the Call   \n",
       "2  Potential Interest as a Lead   \n",
       "3   Definitive Sale on the Call   \n",
       "4   Definitive Sale on the Call   \n",
       "5   Definitive Sale on the Call   \n",
       "6   Definitive Sale on the Call   \n",
       "7  Potential Interest as a Lead   \n",
       "8   Definitive Sale on the Call   \n",
       "9   Definitive Sale on the Call   \n",
       "\n",
       "                                         Explanation  \n",
       "0  The customer showed interest in the services a...  \n",
       "1  The customer, Heather, explicitly agreed to an...  \n",
       "2  The customer showed interest in porting their ...  \n",
       "3  The customer committed to the service by agree...  \n",
       "4  The customer, Rosa, explicitly committed to se...  \n",
       "5  The customer committed to purchasing services ...  \n",
       "6  The customer committed to upgrading their serv...  \n",
       "7  The customer, Ali, shows interest in installin...  \n",
       "8  The customer explicitly committed to the servi...  \n",
       "9  The customer committed to the service installa...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the classifications list\n",
    "classifications = [\n",
    "    \"Definitive Sale on the Call\",\n",
    "    \"No Interest from Customer\", \n",
    "    \"Potential Interest as a Lead\",\n",
    "    \"Inconclusive\"\n",
    "]\n",
    "\n",
    "# Define the context prompt\n",
    "context_prompt = \"\"\"Analyze this sales call transcript and classify it into one of the following sales process stages based on the customer's level of engagement, interest, and the outcome of the conversation:\n",
    "\n",
    "1. **Definitive Sale on the Call** - Customer commits to purchasing, signs up, or agrees to a contract during this specific call\n",
    "2. **No Interest from Customer** - Customer explicitly declines, shows no interest, or is not a viable prospect\n",
    "3. **Potential Interest as a Lead** - Customer shows some interest, asks questions, or requests information but doesn't commit\n",
    "4. **Inconclusive** - The conversation is unclear or the customer's interest level is not clear\n",
    "\n",
    "Consider the following factors when classifying:\n",
    "- Customer's explicit statements about interest level\n",
    "- Whether any commitment or agreement was made\n",
    "- Customer's tone and engagement level\n",
    "- Specific next steps mentioned\n",
    "- Whether the customer requested follow-up information or meetings\n",
    "- Any objections raised and how they were addressed\n",
    "\n",
    "Focus on the customer's behavior and statements rather than the salesperson's actions. A call should only be classified as \"Definitive Sale on the Call\" if there is clear evidence of a commitment or agreement made during this specific conversation.\"\"\"\n",
    "\n",
    "#Run classify_call_transcripts\n",
    "results_with_sales_stage = classify_call_transcripts(classifications, df, context_prompt, \"Conversation\", \"stage\")\n",
    "results_with_sales_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14b112",
   "metadata": {},
   "source": [
    "# Theme Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57979e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Theme Analysis Functions - No Batching, Parallel Processing Only\n",
    "\n",
    "def _make_api_call(messages: List[Dict], model: str = \"gpt-4o-mini\", max_tokens: int = 2000) -> Dict:\n",
    "    \"\"\"Centralized API call with error handling.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        return json.loads(response.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"API call failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "def _create_theme_prompt(context_prompt: str, transcript: str) -> Tuple[str, str]:\n",
    "    \"\"\"Create system and user prompts for theme generation.\"\"\"\n",
    "    system_prompt = f\"\"\"You are an expert at creating MECE categorization frameworks.\n",
    "\n",
    "Task: {context_prompt}\n",
    "\n",
    "Generate 3-10 themes that are:\n",
    "- Mutually Exclusive: No overlap\n",
    "- Collectively Exhaustive: All content fits\n",
    "\n",
    "Return JSON: {{\"themes\": [{{\"themeName\": \"...\", \"themeDescription\": \"...\"}}], \"mece_validation\": \"...\"}}\"\"\"\n",
    "\n",
    "    user_prompt = f\"Analyze this transcript and create MECE themes:\\n\\n{transcript}\"\n",
    "    \n",
    "    return system_prompt, user_prompt\n",
    "\n",
    "def _create_classification_prompt(context_prompt: str, themes: List[Theme], transcript: str, single_theme: bool = True) -> Tuple[str, str]:\n",
    "    \"\"\"Create prompts for transcript classification.\"\"\"\n",
    "    themes_text = \"\\n\".join([f\"- {t.themeName}: {t.themeDescription}\" for t in themes])\n",
    "    instruction = \"Assign exactly ONE theme\" if single_theme else \"Assign one or more themes\"\n",
    "    \n",
    "    system_prompt = f\"\"\"Classify transcript using these themes:\n",
    "\n",
    "{themes_text}\n",
    "\n",
    "Rules:\n",
    "1. {instruction}\n",
    "2. Use only provided themes\n",
    "3. Assign transcript to at least one theme\n",
    "\n",
    "Return JSON: {{\"classifications\": {{\"id\": [\"Theme\"]}}}}\"\"\"\n",
    "\n",
    "    user_prompt = f\"Context: {context_prompt}\\n\\nTranscript:\\n{transcript}\"\n",
    "    \n",
    "    return system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42142e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_themes_parallel(dataframe: pd.DataFrame, transcript_column: str, context_prompt: str, max_workers: int = 4) -> List[Theme]:\n",
    "    \"\"\"Generate themes using parallel processing - no batching, each transcript processed individually.\"\"\"\n",
    "    def process_single_transcript(row):\n",
    "        transcript = row[transcript_column]\n",
    "        system_prompt, user_prompt = _create_theme_prompt(context_prompt, transcript)\n",
    "        \n",
    "        response = _make_api_call([\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ])\n",
    "        \n",
    "        return [Theme(**theme) for theme in response.get(\"themes\", [])]\n",
    "    \n",
    "    print(f\"Generating themes from {len(dataframe)} individual transcripts...\")\n",
    "    \n",
    "    # Process each transcript individually in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        transcript_results = list(executor.map(process_single_transcript, [row for _, row in dataframe.iterrows()]))\n",
    "    \n",
    "    # Flatten results\n",
    "    all_themes = [theme for transcript_themes in transcript_results for theme in transcript_themes]\n",
    "    \n",
    "    print(f\"Generated {len(all_themes)} total themes from individual transcripts\")\n",
    "    \n",
    "    # Merge similar themes\n",
    "    if len(all_themes) > 1:\n",
    "        return _merge_themes(all_themes, context_prompt)\n",
    "    \n",
    "    return all_themes\n",
    "\n",
    "def _merge_themes(themes: List[Theme], context_prompt: str) -> List[Theme]:\n",
    "    \"\"\"Merge similar themes semantically.\"\"\"\n",
    "    themes_text = \"\\n\".join([f\"- {t.themeName}: {t.themeDescription}\" for t in themes])\n",
    "    \n",
    "    system_prompt = f\"\"\"Merge similar themes while maintaining MECE principles.\n",
    "\n",
    "Task: {context_prompt}\n",
    "\n",
    "Merge these themes into 3-10 final themes:\n",
    "{themes_text}\n",
    "\n",
    "Return JSON: {{\"themes\": [{{\"themeName\": \"...\", \"themeDescription\": \"...\"}}], \"mece_validation\": \"...\"}}\"\"\"\n",
    "\n",
    "    user_prompt = \"Create final MECE framework by merging similar themes.\"\n",
    "    \n",
    "    response = _make_api_call([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ])\n",
    "    \n",
    "    return [Theme(**theme) for theme in response.get(\"themes\", themes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7eeb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _classify_transcripts_parallel(dataframe: pd.DataFrame, transcript_column: str, themes: List[Theme], \n",
    "                                 context_prompt: str, id_column: str, single_theme: bool = True, \n",
    "                                 max_workers: int = 4) -> Tuple[Dict[str, List[str]], str]:\n",
    "    \"\"\"Classify transcripts using parallel processing - no batching, each transcript processed individually.\"\"\"\n",
    "    def process_single_transcript(row):\n",
    "        transcript = row[transcript_column]\n",
    "        transcript_id = str(row[id_column])\n",
    "        system_prompt, user_prompt = _create_classification_prompt(context_prompt, themes, transcript, single_theme)\n",
    "        \n",
    "        response = _make_api_call([\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ])\n",
    "        \n",
    "        # Extract classification for this single transcript\n",
    "        classifications = response.get(\"classifications\", {})\n",
    "        # The response should have a single \"id\" key, but we'll use the actual transcript_id\n",
    "        if \"id\" in classifications:\n",
    "            return {transcript_id: classifications[\"id\"]}\n",
    "        else:\n",
    "            return {transcript_id: [\"Unclassified\"]}\n",
    "    \n",
    "    print(f\"Classifying {len(dataframe)} individual transcripts...\")\n",
    "    \n",
    "    # Process each transcript individually in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        transcript_results = list(executor.map(process_single_transcript, [row for _, row in dataframe.iterrows()]))\n",
    "    \n",
    "    # Merge all classifications\n",
    "    all_classifications = {}\n",
    "    for transcript_result in transcript_results:\n",
    "        all_classifications.update(transcript_result)\n",
    "    \n",
    "    return all_classifications, f\"Generated {len(themes)} themes. Classified {len(all_classifications)} transcripts.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde3cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mece_theme_analysis(\n",
    "    dataframe: pd.DataFrame,\n",
    "    transcript_column: str,\n",
    "    context_prompt: str,\n",
    "    id_column: str = None,\n",
    "    target_column: str = \"Theme_Analysis\",\n",
    "    themes_per_transcript: Union[int, str] = 1,\n",
    "    max_workers: int = 4\n",
    ") -> Tuple[pd.DataFrame, MECEThemeAnalysis]:\n",
    "    \"\"\"\n",
    "    Optimized MECE theme analysis with parallel processing - no batching.\n",
    "    Each transcript is processed individually in parallel.\n",
    "    \n",
    "    Args:\n",
    "        dataframe: DataFrame with transcript data\n",
    "        transcript_column: Column containing transcript text\n",
    "        context_prompt: Analysis context/question\n",
    "        id_column: ID column (defaults to first column)\n",
    "        target_column: Output column name\n",
    "        themes_per_transcript: 1 for single theme, \"multiple\" for multiple themes\n",
    "        max_workers: Number of parallel workers\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (DataFrame with themes, MECE analysis results)\n",
    "    \"\"\"\n",
    "    id_column = id_column or dataframe.columns[0]\n",
    "    single_theme = themes_per_transcript == 1\n",
    "    \n",
    "    print(f\"MECE Analysis: {len(dataframe)} transcripts (no batching, parallel processing)\")\n",
    "    \n",
    "    # Phase 1: Generate themes\n",
    "    themes = _generate_themes_parallel(dataframe, transcript_column, context_prompt, max_workers)\n",
    "    if not themes:\n",
    "        return dataframe.assign(**{target_column: \"Error: No themes generated\"}), MECEThemeAnalysis(\n",
    "            themes=[], theme_mappings={}, mece_validation=\"Error\"\n",
    "        )\n",
    "    \n",
    "    print(f\"Generated {len(themes)} themes\")\n",
    "    \n",
    "    # Phase 2: Classify transcripts\n",
    "    theme_mappings, mece_validation = _classify_transcripts_parallel(\n",
    "        dataframe, transcript_column, themes, context_prompt, id_column, single_theme, max_workers\n",
    "    )\n",
    "    \n",
    "    # Apply themes to dataframe\n",
    "    result_df = dataframe.copy()\n",
    "    if single_theme:\n",
    "        theme_map = {str(id_val): themes[0] if themes else \"Unclassified\" \n",
    "                    for id_val, themes in theme_mappings.items()}\n",
    "        result_df[target_column] = result_df[id_column].astype(str).map(theme_map).fillna(\"Unclassified\")\n",
    "    else:\n",
    "        theme_map = {str(id_val): \", \".join(themes) if themes else \"Unclassified\" \n",
    "                    for id_val, themes in theme_mappings.items()}\n",
    "        result_df[target_column] = result_df[id_column].astype(str).map(theme_map).fillna(\"Unclassified\")\n",
    "    \n",
    "    return result_df, MECEThemeAnalysis(\n",
    "        themes=themes,\n",
    "        theme_mappings=theme_mappings,\n",
    "        mece_validation=mece_validation\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f348c",
   "metadata": {},
   "source": [
    "Theme Analysis Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9e7075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MECE Analysis: 10 transcripts (no batching, parallel processing)\n",
      "Generating themes from 10 individual transcripts...\n",
      "Generated 71 total themes from individual transcripts\n",
      "Generated 9 themes\n",
      "Classifying 10 individual transcripts...\n",
      "ðŸ“Š Results:\n",
      "  NaturalId       sales_technique\n",
      "0     Call1  Consultative Selling\n",
      "1    Call10  Consultative Selling\n",
      "2   Call100         Cross-Selling\n",
      "3   Call101  Consultative Selling\n",
      "4   Call102      Building Rapport\n",
      "5   Call103      Building Rapport\n",
      "6   Call104  Consultative Selling\n",
      "7   Call105  Consultative Selling\n",
      "8   Call106  Consultative Selling\n",
      "9   Call107  Consultative Selling\n",
      "\n",
      "ðŸŽ¯ Generated Themes:\n",
      "1. Consultative Selling: The agent engages in a dialogue to understand the customer's specific needs and challenges, asking probing questions to tailor solutions that align with the customer's business requirements.\n",
      "2. Value Proposition Highlighting: The agent emphasizes the benefits and features of the service, including speed, reliability, and cost savings, to create a compelling case for the customer to choose their service.\n",
      "3. Cross-Selling: The agent introduces additional services, such as mobile plans and pro Wi-Fi, to enhance the customer's overall package and provide potential savings, thereby increasing the overall value of the sale.\n",
      "4. Urgency Creation: The agent creates a sense of urgency by emphasizing the importance of timely service installation and the immediate need for high-speed internet, encouraging quicker decision-making.\n",
      "5. Building Rapport: The agent establishes a friendly and personable connection with the customer through casual conversation, empathy, and acknowledgment of their specific situation, fostering a positive relationship.\n",
      "6. Objection Handling: The agent addresses potential customer concerns and hesitations by providing reassurances about contract flexibility, service guarantees, and clarifying any misunderstandings.\n",
      "7. Follow-Up Assurance: The agent commits to sending follow-up communication summarizing the conversation and providing ongoing support, reinforcing trust and ensuring the customer feels secure in their decision.\n",
      "8. Promotional Incentives: The agent highlights promotional offers and discounts to incentivize the customer to make a purchase decision quickly, enhancing the perceived value of the service.\n",
      "9. Risk Mitigation: The agent reassures the customer about the lack of contracts and the availability of a money-back guarantee, which mitigates perceived risk and encourages the customer to proceed with the purchase.\n",
      "\n",
      "âœ… MECE Validation: Generated 9 themes. Classified 10 transcripts.\n"
     ]
    }
   ],
   "source": [
    "# Define your analysis question\n",
    "context_prompt = \"Identify the primary sales techniques or methodologies used by the sales agent in each call transcript. Focus on approaches used to convert the customer that are OUTSIDE OF logistical or product-based selling. The techniques should be a specific, commonly recognized sales strategy.\"\n",
    "\n",
    "# Run MECE theme analysis\n",
    "theme_results, analysis = mece_theme_analysis(\n",
    "    dataframe=results_with_sales_stage,\n",
    "    transcript_column='Conversation',\n",
    "    context_prompt=context_prompt,\n",
    "    id_column='NaturalId',\n",
    "    target_column='sales_technique',\n",
    "    themes_per_transcript=1,  # Single theme per transcript\n",
    "    max_workers=4\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"ðŸ“Š Results:\")\n",
    "print(theme_results[['NaturalId', 'sales_technique']])\n",
    "\n",
    "print(\"\\nðŸŽ¯ Generated Themes:\")\n",
    "for i, theme in enumerate(analysis.themes, 1):\n",
    "    print(f\"{i}. {theme.themeName}: {theme.themeDescription}\")\n",
    "\n",
    "print(f\"\\nâœ… MECE Validation: {analysis.mece_validation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d463c0",
   "metadata": {},
   "source": [
    "# Unique Value Splitter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3477c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_value_splitter(\n",
    "    dataframe: pd.DataFrame,\n",
    "    splitter_column: str\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split a dataframe into separate dataframes based on unique values in a specified column.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame to split\n",
    "        splitter_column (str): Name of the column to use for splitting\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Dictionary where keys are unique values and values are filtered DataFrames\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get unique values from the splitter column\n",
    "    unique_values = dataframe[splitter_column].unique()\n",
    "    \n",
    "    print(f\"Splitting dataframe into {len(unique_values)} groups based on '{splitter_column}' column...\")\n",
    "    print(f\"Unique values found: {list(unique_values)}\")\n",
    "    \n",
    "    # Create dictionary to store split dataframes\n",
    "    split_dataframes = {}\n",
    "    \n",
    "    # Split dataframe for each unique value\n",
    "    for value in unique_values:\n",
    "        # Filter dataframe for current value\n",
    "        filtered_df = dataframe[dataframe[splitter_column] == value].copy()\n",
    "        \n",
    "        # Store in dictionary with value as key\n",
    "        split_dataframes[str(value)] = filtered_df\n",
    "        \n",
    "        print(f\"  - '{value}': {len(filtered_df)} rows\")\n",
    "    \n",
    "    print(\"Dataframe splitting complete!\")\n",
    "    \n",
    "    return split_dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee80e09",
   "metadata": {},
   "source": [
    "Split Dataframe w/ Outcome Stage and Sales Technique by Outcome Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857b0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use unique_value_splitter on categorized_results\n",
    "split_results = unique_value_splitter(theme_results, \"stage\")\n",
    "\n",
    "# Display the split results\n",
    "print(\"\\nSplit DataFrames:\")\n",
    "for group_name, group_df in split_results.items():\n",
    "    print(f\"\\n{group_name} ({len(group_df)} rows):\")\n",
    "    display(group_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c238a3",
   "metadata": {},
   "source": [
    "Access a specific split DataFrame by its group name -- e.g. split_results[\"Definitive Sale on the Call\"]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_results[\"Potential Interest as a Lead\"]\n",
    "#split_results[\"Definitive Sale on the Call\"]\n",
    "#split_results[\"No Interest from Customer\"]\n",
    "#split_results[\"Inconclusive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b99dfb",
   "metadata": {},
   "source": [
    "# Comparator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ea74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# -------------------------------\n",
    "# Schema for structured comparison\n",
    "# -------------------------------\n",
    "class GroupSummary(BaseModel):\n",
    "    group_name: str\n",
    "    summary: str\n",
    "\n",
    "class ComparisonOutput(BaseModel):\n",
    "    introduction: str\n",
    "    key_findings: List[str]\n",
    "    similarities: List[str]\n",
    "    differences: List[str]\n",
    "    group_summaries: List[GroupSummary]\n",
    "\n",
    "# -------------------------------\n",
    "# Comparison function\n",
    "# -------------------------------\n",
    "def comparison_function(grouped_dfs: Dict[str, pd.DataFrame],\n",
    "                        columns_to_analyze: List[str],\n",
    "                        context_prompt: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare multiple groups of dataframes directly against each other.\n",
    "\n",
    "    Args:\n",
    "        grouped_dfs: dictionary of {group_name: dataframe}\n",
    "        columns_to_analyze: list of column names to analyze\n",
    "        context_prompt: guiding analysis question (e.g. \"What makes sales calls effective?\")\n",
    "    \n",
    "    Returns:\n",
    "        Dict with overall comparison, similarities, differences, and group summaries\n",
    "    \"\"\"\n",
    "    # Build compact summaries for each group\n",
    "    group_texts = {}\n",
    "    for group_name, df in grouped_dfs.items():\n",
    "        sample_text = df[columns_to_analyze].astype(str).apply(lambda row: \" | \".join(row), axis=1)\n",
    "        combined_text = \"\\n\".join(sample_text.tolist()[:150])  # cap records per group\n",
    "        group_texts[group_name] = combined_text\n",
    "\n",
    "    # Prepare prompt with all groups\n",
    "    group_descriptions = \"\\n\\n\".join(\n",
    "        [f\"### {name}:\\n{txt}\" for name, txt in group_texts.items()]\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are an expert data analyst. Your job is to compare groups of records,\n",
    "            identify similarities and differences, and explain what variables contribute to outcomes.\n",
    "            Always return valid JSON matching the schema.\n",
    "            \"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Context: {context_prompt}\n",
    "\n",
    "            Here are the grouped records (truncated samples shown for each):\n",
    "\n",
    "            {group_descriptions}\n",
    "\n",
    "            Please provide:\n",
    "            - overall_comparison: a narrative comparing all groups directly\n",
    "            - similarities: what traits or variables appear across groups\n",
    "            - differences: what distinguishes successful vs unsuccessful outcomes\n",
    "            - group_summaries: return as a JSON list of objects, each with keys \"group_name\" and \"summary\"\n",
    "            \"\"\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.responses.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=messages,\n",
    "            text_format=ComparisonOutput,\n",
    "            temperature=0,\n",
    "            max_output_tokens=800,\n",
    "        )\n",
    "\n",
    "        parsed: ComparisonOutput = response.output_parsed\n",
    "        return parsed.model_dump()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Comparison failed: {e}\")\n",
    "        return {\n",
    "            \"overall_comparison\": \"No comparison generated\",\n",
    "            \"similarities\": \"N/A\",\n",
    "            \"differences\": \"N/A\",\n",
    "            \"group_summaries\": [{\"group_name\": name, \"summary\": \"No summary\"} for name in grouped_dfs.keys()]\n",
    "        }\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dfs = {\n",
    "    \"Definitive Sale\": split_results[\"Definitive Sale on the Call\"],\n",
    "    \"Potential Interest\": split_results[\"Potential Interest as a Lead\"],\n",
    "}\n",
    "\n",
    "results = comparison_function(\n",
    "    grouped_dfs=grouped_dfs,\n",
    "    columns_to_analyze=[\"Sales_Technique_Used\"],\n",
    "    context_prompt=\"Compare sales call outcomes. What makes sales calls effective vs ineffective?\"\n",
    ")\n",
    "\n",
    "# Print clean structured output\n",
    "print(\"\\n=== INTRODUCTION ===\")\n",
    "print(results[\"introduction\"])\n",
    "\n",
    "print(\"\\n=== KEY FINDINGS ===\")\n",
    "for finding in results[\"key_findings\"]:\n",
    "    print(f\"- {finding}\")\n",
    "\n",
    "print(\"\\n=== SIMILARITIES ===\")\n",
    "for sim in results[\"similarities\"]:\n",
    "    print(f\"- {sim}\")\n",
    "\n",
    "print(\"\\n=== DIFFERENCES ===\")\n",
    "for diff in results[\"differences\"]:\n",
    "    print(f\"- {diff}\")\n",
    "\n",
    "print(\"\\n=== GROUP SUMMARIES ===\")\n",
    "for summary in results[\"group_summaries\"]:\n",
    "    print(f\"[{summary['group_name']}] {summary['summary']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
